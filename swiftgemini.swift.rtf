{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red183\green111\blue247;\red23\green24\blue24;\red202\green202\blue202;
\red54\green192\blue160;\red109\green115\blue120;\red212\green212\blue212;\red125\green125\blue125;\red246\green124\blue48;
\red113\green192\blue131;}
{\*\expandedcolortbl;;\cssrgb\c77255\c54118\c97647;\cssrgb\c11765\c12157\c12549;\cssrgb\c83137\c83137\c83137;
\cssrgb\c23922\c78824\c69020;\cssrgb\c50196\c52549\c54510;\cssrgb\c86275\c86275\c86275;\cssrgb\c56471\c56471\c56471;\cssrgb\c98039\c56471\c24314;
\cssrgb\c50588\c78824\c58431;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 Foundation\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 // MARK: - Data Structures\cf4 \cb1 \strokec4 \
\
\cf6 \cb3 \strokec6 /// Represents a single claim with its features and verification outcome.\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 struct\cf4 \strokec4  \cf5 \strokec5 ClaimData\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cf2 \strokec2 let\cf4 \strokec4  id\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 String\cf4 \strokec4  \cf6 \strokec6 // Unique identifier for the claim\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  isVerifiedTrue\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Bool\cf4 \strokec4  \cf6 \strokec6 // Observation y_i in \{0, 1\}\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 // Features of the claim x_i\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  riskAuthenticity\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf6 \strokec6 // R_a\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  riskVirality\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4      \cf6 \strokec6 // R_v\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  probabilityHgivenE\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf6 \strokec6 // P(H|E)\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 \}\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 /// Holds the hyperparameters for the prior distributions.\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 struct\cf4 \strokec4  \cf5 \strokec5 ModelPriors\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cf6 \strokec6 // Beta priors for S, N, alpha\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  s_alpha\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  s_beta\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  n_alpha\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  n_beta\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  alpha_alpha\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  alpha_beta\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 // LogNormal prior for beta\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  beta_mu\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 0.0\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  beta_sigma\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 // Gamma priors for R_a, R_v\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  ra_shape\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \strokec4  \cf6 \strokec6 // k_a\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  ra_scale\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \strokec4  \cf6 \strokec6 // theta_a\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  rv_shape\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \strokec4  \cf6 \strokec6 // k_v\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  rv_scale\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1.0\cf4 \strokec4  \cf6 \strokec6 // theta_v\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 // Hyperparameters for the penalty function\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  lambda1\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 0.1\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  lambda2\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 0.1\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 \}\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 /// Represents a single sample of the model parameters from the posterior distribution.\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 struct\cf4 \strokec4  \cf5 \strokec5 ModelParameters\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cf6 \strokec6 // Parameters to be inferred\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  \cf5 \strokec5 S\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4        \cf6 \strokec6 // S ~ Beta(a_S, b_S)\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  \cf5 \strokec5 N\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4        \cf6 \strokec6 // N ~ Beta(a_N, b_N)\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  alpha\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4    \cf6 \strokec6 // alpha ~ Beta(a_alpha, b_alpha)\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  beta\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4     \cf6 \strokec6 // beta ~ LogNormal(mu_beta, sigma_beta)\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 // Note: R_a and R_v are features of the data `x_i`, not global model parameters.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 // The priors for R_a and R_v in the model description might imply a model\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 // where these are latent variables, but the text describes them as claim features.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 // This implementation assumes they are part of `ClaimData`.\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 \}\cf4 \cb1 \strokec4 \
\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 // MARK: - Hierarchical Bayesian Model\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 class\cf4 \strokec4  \cf5 \strokec5 HierarchicalBayesianModel\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cb1 \
\cb3     \cf2 \strokec2 let\cf4 \strokec4  priors\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ModelPriors\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf2 \strokec2 init\cf7 \strokec7 (\cf4 \strokec4 priors\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ModelPriors\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf5 \strokec5 ModelPriors\cf7 \strokec7 ())\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 self\cf4 \strokec4 .\cf5 \strokec5 priors\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  priors\cb1 \
\cb3     \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 // MARK: - Core Model Equations\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 /// Calculates the event probability Psi(x) for a given claim and model parameters.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// This is the "Link" function in your model specification.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// - Parameters:\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///   - claim: The claim data `x_i`.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///   - params: A sample of the model parameters.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// - Returns: The calculated event probability, bounded in [0, 1].\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 func\cf4 \strokec4  calculatePsi\cf7 \strokec7 (\cf2 \strokec2 for\cf4 \strokec4  claim\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ClaimData\cf8 \strokec8 ,\cf4 \strokec4  with params\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ModelParameters\cf7 \strokec7 )\cf4 \strokec4  \cf8 \strokec8 ->\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 // O = \uc0\u945 S + (1 - \u945 )N\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  \cf5 \strokec5 O\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  params.\cf5 \strokec5 alpha\cf4 \strokec4  \cf8 \strokec8 *\cf4 \strokec4  params.\cf5 \strokec5 S\cf4 \strokec4  \cf8 \strokec8 +\cf4 \strokec4  \cf7 \strokec7 (\cf9 \strokec9 1.0\cf4 \strokec4  \cf8 \strokec8 -\cf4 \strokec4  params.\cf5 \strokec5 alpha\cf7 \strokec7 )\cf4 \strokec4  \cf8 \strokec8 *\cf4 \strokec4  params.\cf5 \strokec5 N\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // pen = exp(-[\uc0\u955 1*R_a + \u955 2*R_v])\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  penaltyExponent \cf8 \strokec8 =\cf4 \strokec4  \cf8 \strokec8 -\cf7 \strokec7 (\cf4 \strokec4 priors.\cf5 \strokec5 lambda1\cf4 \strokec4  \cf8 \strokec8 *\cf4 \strokec4  claim.\cf5 \strokec5 riskAuthenticity\cf4 \strokec4  \cf8 \strokec8 +\cf4 \strokec4  priors.\cf5 \strokec5 lambda2\cf4 \strokec4  \cf8 \strokec8 *\cf4 \strokec4  claim.\cf5 \strokec5 riskVirality\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  pen \cf8 \strokec8 =\cf4 \strokec4  exp\cf7 \strokec7 (\cf4 \strokec4 penaltyExponent\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // P(H|E, \uc0\u946 ) = min\{\u946  * P(H|E), 1\}\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  p_H_given_E_beta \cf8 \strokec8 =\cf4 \strokec4  min\cf7 \strokec7 (\cf4 \strokec4 params.\cf5 \strokec5 beta\cf4 \strokec4  \cf8 \strokec8 *\cf4 \strokec4  claim.\cf5 \strokec5 probabilityHgivenE\cf8 \strokec8 ,\cf4 \strokec4  \cf9 \strokec9 1.0\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // \uc0\u936 (x) = O * pen * P(H|E, \u946 )\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  psi \cf8 \strokec8 =\cf4 \strokec4  \cf5 \strokec5 O\cf4 \strokec4  \cf8 \strokec8 *\cf4 \strokec4  pen \cf8 \strokec8 *\cf4 \strokec4  p_H_given_E_beta\cb1 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // Ensure the result is strictly within [0, 1] for numerical stability\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 return\cf4 \strokec4  max\cf7 \strokec7 (\cf9 \strokec9 0.0\cf8 \strokec8 ,\cf4 \strokec4  min\cf7 \strokec7 (\cf9 \strokec9 1.0\cf8 \strokec8 ,\cf4 \strokec4  psi\cf7 \strokec7 ))\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 // MARK: - Likelihood and Posterior\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 /// Calculates the log-likelihood of a single data point (y_i).\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// y_i | \uc0\u936 (x_i) ~ Bernoulli(\u936 (x_i))\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// - Parameters:\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///   - claim: The claim data containing the observation `y_i`.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///   - params: A sample of the model parameters.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// - Returns: The log-likelihood for the observation.\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 func\cf4 \strokec4  logLikelihood\cf7 \strokec7 (\cf2 \strokec2 for\cf4 \strokec4  claim\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ClaimData\cf8 \strokec8 ,\cf4 \strokec4  with params\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ModelParameters\cf7 \strokec7 )\cf4 \strokec4  \cf8 \strokec8 ->\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  psi \cf8 \strokec8 =\cf4 \strokec4  calculatePsi\cf7 \strokec7 (\cf2 \strokec2 for\cf8 \strokec8 :\cf4 \strokec4  claim\cf8 \strokec8 ,\cf4 \strokec4  with\cf8 \strokec8 :\cf4 \strokec4  params\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // Avoid log(0) by clamping psi\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  epsilon \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 1\cf4 \strokec4 e\cf8 \strokec8 -9\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  clampedPsi \cf8 \strokec8 =\cf4 \strokec4  max\cf7 \strokec7 (\cf4 \strokec4 epsilon\cf8 \strokec8 ,\cf4 \strokec4  min\cf7 \strokec7 (\cf9 \strokec9 1.0\cf4 \strokec4  \cf8 \strokec8 -\cf4 \strokec4  epsilon\cf8 \strokec8 ,\cf4 \strokec4  psi\cf7 \strokec7 ))\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf2 \strokec2 if\cf4 \strokec4  claim.\cf5 \strokec5 isVerifiedTrue\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3             \cf2 \strokec2 return\cf4 \strokec4  log\cf7 \strokec7 (\cf4 \strokec4 clampedPsi\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cf7 \strokec7 \}\cf4 \strokec4  \cf2 \strokec2 else\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3             \cf2 \strokec2 return\cf4 \strokec4  log\cf7 \strokec7 (\cf9 \strokec9 1.0\cf4 \strokec4  \cf8 \strokec8 -\cf4 \strokec4  clampedPsi\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 /// Calculates the total log-likelihood for a dataset.\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 func\cf4 \strokec4  totalLogLikelihood\cf7 \strokec7 (\cf2 \strokec2 for\cf4 \strokec4  dataset\cf8 \strokec8 :\cf4 \strokec4  \cf7 \strokec7 [\cf5 \strokec5 ClaimData\cf7 \strokec7 ]\cf8 \strokec8 ,\cf4 \strokec4  with params\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ModelParameters\cf7 \strokec7 )\cf4 \strokec4  \cf8 \strokec8 ->\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 return\cf4 \strokec4  dataset.\cf5 \strokec5 reduce\cf7 \strokec7 (\cf9 \strokec9 0.0\cf7 \strokec7 )\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \strokec4  \cf7 \strokec7 (\cf4 \strokec4 total\cf8 \strokec8 ,\cf4 \strokec4  claim\cf7 \strokec7 )\cf4 \strokec4  \cf8 \strokec8 ->\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf2 \strokec2 in\cf4 \cb1 \strokec4 \
\cb3             total \cf8 \strokec8 +\cf4 \strokec4  logLikelihood\cf7 \strokec7 (\cf2 \strokec2 for\cf8 \strokec8 :\cf4 \strokec4  claim\cf8 \strokec8 ,\cf4 \strokec4  with\cf8 \strokec8 :\cf4 \strokec4  params\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 /// Calculates the log-probability of the priors for a given set of parameters.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// This would require functions for the log-PDF of Beta, LogNormal, etc.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// - Parameter params: A sample of the model parameters.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// - Returns: The sum of the log-prior probabilities.\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 func\cf4 \strokec4  logPriors\cf7 \strokec7 (\cf2 \strokec2 for\cf4 \strokec4  params\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ModelParameters\cf7 \strokec7 )\cf4 \strokec4  \cf8 \strokec8 ->\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 // Note: This is a placeholder. A full implementation would need\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 // statistical distribution functions (e.g., from a library).\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 var\cf4 \strokec4  logPriorSum \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 0.0\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 // logPriorSum += logBetaPDF(params.S, alpha: priors.s_alpha, beta: priors.s_beta)\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 // logPriorSum += logBetaPDF(params.N, alpha: priors.n_alpha, beta: priors.n_beta)\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 // ... and so on for all parameters.\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // For now, returning 0 assumes uniform priors for simplicity.\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 return\cf4 \strokec4  logPriorSum\cb1 \
\cb3     \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 /// Calculates the log-posterior, which is proportional to log-likelihood + log-priors.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// This is the target function for MCMC samplers.\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 func\cf4 \strokec4  logPosterior\cf7 \strokec7 (\cf2 \strokec2 for\cf4 \strokec4  dataset\cf8 \strokec8 :\cf4 \strokec4  \cf7 \strokec7 [\cf5 \strokec5 ClaimData\cf7 \strokec7 ]\cf8 \strokec8 ,\cf4 \strokec4  with params\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 ModelParameters\cf7 \strokec7 )\cf4 \strokec4  \cf8 \strokec8 ->\cf4 \strokec4  \cf5 \strokec5 Double\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  likelihood \cf8 \strokec8 =\cf4 \strokec4  totalLogLikelihood\cf7 \strokec7 (\cf2 \strokec2 for\cf8 \strokec8 :\cf4 \strokec4  dataset\cf8 \strokec8 ,\cf4 \strokec4  with\cf8 \strokec8 :\cf4 \strokec4  params\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  priors \cf8 \strokec8 =\cf4 \strokec4  logPriors\cf7 \strokec7 (\cf2 \strokec2 for\cf8 \strokec8 :\cf4 \strokec4  params\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 return\cf4 \strokec4  likelihood \cf8 \strokec8 +\cf4 \strokec4  priors\cb1 \
\cb3     \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 // MARK: - Inference (Placeholder)\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf6 \strokec6 /// Performs posterior inference using an MCMC method like HMC/NUTS.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// **NOTE:** Swift does not have a built-in, standard library for probabilistic\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// programming or MCMC sampling (like Python's PyMC or Stan). This function\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// is a placeholder for where you would integrate a third-party library\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// or a custom-built sampler.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 ///\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// - Parameter dataset: The collection of observed claims.\cf4 \cb1 \strokec4 \
\cb3     \cf6 \strokec6 /// - Returns: An array of parameter samples from the posterior distribution.\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 func\cf4 \strokec4  performInference\cf7 \strokec7 (\cf4 \strokec4 dataset\cf8 \strokec8 :\cf4 \strokec4  \cf7 \strokec7 [\cf5 \strokec5 ClaimData\cf7 \strokec7 ]\cf8 \strokec8 ,\cf4 \strokec4  sampleCount\cf8 \strokec8 :\cf4 \strokec4  \cf5 \strokec5 Int\cf7 \strokec7 )\cf4 \strokec4  \cf8 \strokec8 ->\cf4 \strokec4  \cf7 \strokec7 [\cf5 \strokec5 ModelParameters\cf7 \strokec7 ]\cf4 \strokec4  \cf7 \strokec7 \{\cf4 \cb1 \strokec4 \
\cb3         print\cf7 \strokec7 (\cf10 \strokec10 "Starting inference..."\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // 1. Define the initial state for the sampler.\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  initialParams \cf8 \strokec8 =\cf4 \strokec4  \cf5 \strokec5 ModelParameters\cf7 \strokec7 (\cf5 \strokec5 S\cf8 \strokec8 :\cf4 \strokec4  \cf9 \strokec9 0.5\cf8 \strokec8 ,\cf4 \strokec4  \cf5 \strokec5 N\cf8 \strokec8 :\cf4 \strokec4  \cf9 \strokec9 0.5\cf8 \strokec8 ,\cf4 \strokec4  alpha\cf8 \strokec8 :\cf4 \strokec4  \cf9 \strokec9 0.5\cf8 \strokec8 ,\cf4 \strokec4  beta\cf8 \strokec8 :\cf4 \strokec4  \cf9 \strokec9 1.0\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // 2. Set up the MCMC sampler (e.g., HMC/NUTS).\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 //    The sampler would need the log-posterior function as its target.\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 //    let sampler = HMCSampler(targetLogProb: \{ params in\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 //        self.logPosterior(for: dataset, with: params)\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 //    \})\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // 3. Run the sampler.\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 //    let samples = sampler.run(from: initialParams, count: sampleCount)\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         print\cf7 \strokec7 (\cf10 \strokec10 "Inference placeholder finished."\cf7 \strokec7 )\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         \cf6 \strokec6 // Returning an empty array as this is a skeleton.\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 let\cf4 \strokec4  posteriorSamples\cf8 \strokec8 :\cf4 \strokec4  \cf7 \strokec7 [\cf5 \strokec5 ModelParameters\cf7 \strokec7 ]\cf4 \strokec4  \cf8 \strokec8 =\cf4 \strokec4  \cf7 \strokec7 []\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 return\cf4 \strokec4  posteriorSamples\cb1 \
\cb3     \cf7 \strokec7 \}\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 \}\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 // MARK: - Example Usage\cf4 \cb1 \strokec4 \
\
\cf6 \cb3 \strokec6 // let model = HierarchicalBayesianModel()\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 //\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 // // Create some dummy data\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 // let claims: [ClaimData] = [\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 //     ClaimData(id: "claim1", isVerifiedTrue: true, riskAuthenticity: 0.2, riskVirality: 0.8, probabilityHgivenE: 0.6),\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 //     ClaimData(id: "claim2", isVerifiedTrue: false, riskAuthenticity: 0.9, riskVirality: 0.5, probabilityHgivenE: 0.3),\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 //     // ... more data\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 // ]\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 //\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 // // Run the inference to get posterior samples\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 // let posteriorSamples = model.performInference(dataset: claims, sampleCount: 2000)\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 //\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 // // After getting samples, you can calculate the posterior of Psi for a new claim\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 // // and its credible intervals.\cf4 \cb1 \strokec4 \
\
}